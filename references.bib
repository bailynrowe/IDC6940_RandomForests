@article{su2020prediction,
  title={Prediction for cardiovascular diseases based on laboratory data: an analysis of random forest model},
  author={Su, Xi and Xu, Yongyong and Tan, Zhijun and Wang, Xia and Yang, Peng and Su, Yani and Jiang, Yangyang and Qin, Sijia and Shang, Lei},
  journal={Journal of clinical laboratory analysis},
  volume={34},
  number={9},
  pages={e23421},
  year={2020},
  publisher={Wiley Online Library}
}

@inproceedings{xu2017risk,
  title={Risk prediction of type II diabetes based on random forest model},
  author={Xu, Weifeng and Zhang, Jianxin and Zhang, Qiang and Wei, Xiaopeng},
  booktitle={2017 third international conference on advances in electrical, electronics, information, communication and bio-informatics (AEEICB)},
  pages={382--386},
  year={2017},
  organization={IEEE}
}

@article{everingham2016accurate,
  title={Accurate prediction of sugarcane yield using a random forest algorithm},
  author={Everingham, Yvette and Sexton, Justin and Skocaj, Danielle and Inman-Bamber, Geoff},
  journal={Agronomy for sustainable development},
  volume={36},
  pages={1--9},
  year={2016},
  publisher={Springer}
}

@article{chen2020modeling,
  title={Modeling road accident severity with comparisons of logistic regression, decision tree and random forest},
  author={Chen, Mu-Ming and Chen, Mu-Chen},
  journal={Information},
  volume={11},
  number={5},
  pages={270},
  year={2020},
  publisher={MDPI}
}

@article{esmaily2018comparison,
  title={A comparison between decision tree and random forest in determining the risk factors associated with type 2 diabetes},
  author={Esmaily, Habibollah and Tayefi, Maryam and Doosti, Hassan and Ghayour-Mobarhan, Majid and Nezami, Hossein and Amirabadizadeh, Alireza},
  journal={Journal of research in health sciences},
  volume={18},
  number={2},
  pages={412},
  year={2018}
}

@article{thomas2024improved,
  title={An Improved and Optimized Random Forest Based Approach to Predict the Software Faults},
  author={Thomas, Nikhil Saji and Kaliraj, S},
  journal={SN Computer Science},
  volume={5},
  number={5},
  pages={530},
  year={2024},
  publisher={Springer}
}

@article{mao2024can,
  title={Can a Single Tree Outperform an Entire Forest?},
  author={Mao, Qiangqiang and Cao, Yankai},
  journal={arXiv preprint arXiv:2411.17003},
  year={2024}
}

@article{smith2013comparison,
  title={A comparison of random forest regression and multiple linear regression for prediction in neuroscience},
  author={Smith, Paul F and Ganesh, Siva and Liu, Ping},
  journal={Journal of neuroscience methods},
  volume={220},
  number={1},
  pages={85--91},
  year={2013},
  publisher={Elsevier}
}


@inproceedings{bosch2007image,
  title={Image classification using random forests and ferns},
  author={Bosch, Anna and Zisserman, Andrew and Munoz, Xavier},
  booktitle={2007 IEEE 11th international conference on computer vision},
  pages={1--8},
  year={2007},
  organization={Ieee}
}


@article{montgomery2024comparative,
  title={A Comparative Analysis of Decision Trees, Neural Networks, and Bayesian Networks: Methodological Insights and Practical Applications in Machine Learning},
  author={Montgomery, Richard Murdoch},
  year={2024}
}

@article{couronne2018random,
  title={Random forest versus logistic regression: a large-scale benchmark experiment},
  author={Couronn{\'e}, Raphael and Probst, Philipp and Boulesteix, Anne-Laure},
  journal={BMC bioinformatics},
  volume={19},
  pages={1--14},
  year={2018},
  publisher={Springer}
}

@article{kirasich2018random,
  title={Random forest vs logistic regression: binary classification for heterogeneous datasets},
  author={Kirasich, Kaitlin and Smith, Trace and Sadler, Bivin},
  journal={SMU Data Science Review},
  volume={1},
  number={3},
  pages={9},
  year={2018}
}

@article{cushman2018landscape,
  title={Landscape applications of machine learning: comparing random forests and logistic regression in multi-scale optimized predictive modeling of American marten occurrence in northern Idaho, USA},
  author={Cushman, Samuel A and Wasserman, Tzeidle N},
  journal={Machine learning for ecology and sustainable natural resource management},
  pages={185--203},
  year={2018},
  publisher={Springer}
}

@article{article,
author = {Loh, Wei-Yin},
year = {2014},
month = {06},
pages = {},
title = {Fifty Years of Classification and Regression Trees},
volume = {82},
journal = {International Statistical Review},
doi = {10.1111/insr.12016}
}

@misc{cortez_wine_quality_2009,
  author       = {Paulo Cortez and A. Cerdeira and F. Almeida and T. Matos and J. Reis},
  title        = {{Wine Quality} [Dataset]},
  howpublished = {UCI Machine Learning Repository},
  year         = {2009},
  note         = {https://doi.org/10.24432/C56S3T},
}

@article{biau2016random,
  title={A random forest guided tour},
  author={Biau, G{\'e}rard and Scornet, Erwan},
  journal={Test},
  volume={25},
  number={2},
  pages={197--227},
  year={2016},
  publisher={Springer}
}

@article{prajwala2015comparative,
  title={A comparative study on decision tree and random forest using R tool},
  author={Prajwala, TR},
  journal={International journal of advanced research in computer and communication engineering},
  volume={4},
  number={1},
  pages={196--199},
  year={2015}
}

@misc{simplilearn2023randomforest,
  author       = {{Simplilearn}},
  title        = {Random Forest Algorithm - A Complete Guide},
  year         = {2023},
  url          = {https://www.simplilearn.com/tutorials/machine-learning-tutorial/random-forest-algorithm},
  note         = {Accessed: 2025-06-25}
}

@misc{scikit-learn2024decisiontree,
  author       = {{Scikit-learn developers}},
  title        = {Tree-based models â€” scikit-learn 1.4.2 documentation},
  year         = {2024},
  url          = {https://scikit-learn.org/stable/modules/tree.html},
  note         = {Accessed: 2025-06-25}
}

@misc{ibm2024decisiontrees,
  author       = {{IBM Corporation}},
  title        = {What is a Decision Tree?},
  year         = {2024},
  url          = {https://www.ibm.com/think/topics/decision-trees},
  note         = {Accessed: 2025-06-25}
}

@misc{gfg_decision_tree,
  author       = {{GeeksforGeeks}},
  title        = {Decision Tree Algorithms in Machine Learning},
  year         = 2023,
  howpublished = {\url{https://www.geeksforgeeks.org/machine-learning/decision-tree-algorithms/}},
  note         = {Accessed: 2025-06-26}
}

@article{Wibowo2023MaskUseDetection,
  title        = {Mask Use Detection in Public Places Using the Convolutional Neural Network Algorithm},
  author       = {Wibowo, Mochamad Yoga and Hikmayanti, Hanny and Nur Masruriyah, Anis Fitri and Heryana, Nono and others},
  year         = {2023},
  journal      = {ResearchGate},
  note         = {Figure 1: "Confusion Matriks. The confusion matrix is a technique for evaluating the performance of a classification model in machine learning and deep learning."},
}
 

