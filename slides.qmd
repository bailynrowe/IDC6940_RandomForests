---
title: "Using Random Forest to Predict Wine Quality"
subtitle: "Summer 2025"
author: "Bailyn Rowe, Gabriel Gonzalez Rincon, Morgan Watkins (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  revealjs
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!

More information about `revealjs`:
<https://quarto.org/docs/reference/formats/presentations/revealjs.html>
:::

## Introduction 

The idea for decision trees came from Morgan and Sonquist. [@article]

A decision tree is an example of supervised machine learning and Random Forest is an ensemble classifier that builds on the concept of decision trees by adding randomness.

In this presentation, random forest and decision trees are used to predict the quality of wine based on its chemical properties.

## Potential Applications of Random Forest
Random Forest and Decision Tree methodologies can be applied across datasets and industries.

Examples:

-healthcare: risk for cardiovascular disease [@su2020prediction] and diabetes [@xu2017risk]

-agriculture: predict sugarcane production [@everingham2016accurate]

-emergency management: predict severity of highway accidents [@chen2020modeling]
 
## Literature Review  {.smaller}

Medical research used random forest methodology to conduct risk assessment to determine individuals at high risk for cardiovascular diseases and the random forest as a prediction model was helpful in evaluating many possible predictor variables and possible complexities between them. [@su2020prediction]

Modeling Type 2 Diabetes Mellitus is difficult because of the interactions between genetic, environmental, and behavioral factors that classic statistical methods can’t accurately model.Both a decision tree model and a random forest model were created. [@esmaily2018comparison] By looking at both models, it was determined that BMI, triglycerides, and family history were the top risk factors.

Everingham applied random forest to a dataset collected from 1992 to 2013, containing variables relating to weather and soil quality, and used that to predict sugarcane yield. [@everingham2016accurate] While the accuracy of the models is not perfect, combined with other predictions, they can be used as a guide to farming activities and planning.

## Decision Trees
Decision Trees represent a sequence of rules in the shape of a tree or a flowchart.

The decision tree is made up of the root node, the decision nodes, the terminal nodes, and the branches.

There are different algorithms used to make decision trees: ID3, Chi-Square Automatic Interaction Detection, Multivariate Adaptive Regression Splines, and Conditional Inference Trees.

## Classification and Regression Trees (CART)
The CART algorithm is what R Studio uses to create random forests.

CART is useful for both regression and classification.
CART uses Gini impurity to split for classification and variance for regression.

The Gini impurity measures the likelihood of randomly selected data being incorrectly classified. 

$$
Gini(p) = 1 - Σ '(pᵢ²)
$$

## Random Forest

Random forest creates multiple decision trees, then averages the results of each of the decisions made by each individual tree to provide a prediction.

1. Training Data Selection

2. Tree Growth

3. Random Attribute Selection

4. Majority Vote

## Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

## Data Exploration and Visualization {.smaller}

A study was conducted to determine how...

```{r, warning=FALSE, echo=F, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=F}
# Load Data
#kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

## Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

## Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
